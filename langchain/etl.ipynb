{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imports\n",
    "import os\n",
    "import chromadb\n",
    "from langchain_core.documents import Document\n",
    "from chromadbx import UUIDGenerator\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileHelper():\n",
    "    def populate_file_paths(self, dir_path, files):\n",
    "        directories = os.listdir(dir_path)\n",
    "        for dircontent in directories:\n",
    "            if dircontent.startswith(\".\"):\n",
    "                continue\n",
    "            file_path = os.path.join(dir_path, dircontent)\n",
    "            if os.path.isfile(file_path):\n",
    "                files.append(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                self.populate_file_paths(file_path, files)\n",
    "\n",
    "    def load_documents(self, file_path, document_loader):\n",
    "        loader = document_loader(file_path)\n",
    "        return loader.load_and_split()\n",
    "\n",
    "    def read_documents(self, file_paths, document_loader, n_jobs=2):\n",
    "        pages_all = []\n",
    "        pages = Parallel(n_jobs=n_jobs)(delayed(self.load_documents)(file_path, document_loader) for file_path in file_paths)\n",
    "        for page in pages:\n",
    "            pages_all.extend(page)\n",
    "        \n",
    "        return pages_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterHelper():\n",
    "    def batched(self, iterable, n):\n",
    "        if n < 1:\n",
    "            raise ValueError('n must be at least one')\n",
    "\n",
    "        for i in range(0, len(iterable), n):\n",
    "            yield iterable[i: i + n]\n",
    "\n",
    "class TimeHelper():\n",
    "    def get_utc_now(self):\n",
    "        return datetime.datetime.now(datetime.timezone.utc)\n",
    "\n",
    "    def get_elapsed_seconds(self, start_time: datetime):\n",
    "        return (self.get_utc_now() - start_time).total_seconds()\n",
    "\n",
    "class IdHelper():\n",
    "    def new_id(self):\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "    def new_ids(self, num: int):\n",
    "        return [self.new_id() for x in range(num)]\n",
    "   \n",
    "class VectorDbRepository():\n",
    "    def __init__(self, collection_name, repository):\n",
    "        self.collection_name = collection_name\n",
    "        self.repository = repository(collection_name)\n",
    "\n",
    "    def get_or_create_collection(self, collection_name):\n",
    "        return self.repository.get_or_create_collection(collection_name)\n",
    "\n",
    "    def add_to_collection(self, documents_list: list[Document]) -> None:\n",
    "        return self.repository.add_to_collection()\n",
    "        \n",
    "    def get_data_by_source(self, source: str):\n",
    "        return self.repository.get_data_by_source(source)\n",
    "    \n",
    "    def delete_data_by_source(self, source: str):\n",
    "        return self.repository.delete_data_by_source(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaDbRepository():\n",
    "    def __init__(self, collection_name):\n",
    "        self.collection_name = collection_name\n",
    "        self.client = chromadb.PersistentClient()\n",
    "\n",
    "    def get_or_create_collection(self):\n",
    "        return self.client.get_or_create_collection(self.collection_name)\n",
    "\n",
    "    def add_to_collection(self, documents_list: list[Document]) -> None:\n",
    "        ids = IdHelper().new_ids(len(documents_list))\n",
    "        return self.get_or_create_collection().add(ids=ids,\n",
    "                metadatas=[p.metadata for p in documents_list],\n",
    "                documents=[p.page_content for p in documents_list])\n",
    "        \n",
    "    def get_data_by_source(self, source: str):\n",
    "        return self.get_or_create_collection().get(where={\"source\":source})\n",
    "    \n",
    "    def delete_data_by_source(self, source: str):\n",
    "        return self.get_or_create_collection().delete(where={\"source\":source})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MilvusDbRepository():\n",
    "    def __init__(self, collection_name):\n",
    "        self.collection_name = collection_name\n",
    "        self.client = MilvusClient(uri=\"http://localhost:19530\")\n",
    "\n",
    "    def get_or_create_collection(self):\n",
    "        if not self.client.has_collection(self.collection_name):            \n",
    "            self.client.create_collection(self.collection_name)\n",
    "\n",
    "    def add_to_collection(self, documents_list: list[Document]) -> None:\n",
    "        id_helper = IdHelper()\n",
    "        data = []\n",
    "        for document in documents_list:\n",
    "            single_data = page.metadata | {'text': page.page_content}\n",
    "            single_data['id'] = id_helper.new_id()\n",
    "            data.append(single_data)\n",
    "       \n",
    "        return self.client.insert(\n",
    "            collection_name=self.collection_name,\n",
    "            data=data)\n",
    "        \n",
    "    def get_data_by_source(self, source: str):\n",
    "        return self.client.query(\n",
    "            collection_name=self.collection_name,\n",
    "            filter=f\"source == '{source}'\")\n",
    "    \n",
    "    def delete_data_by_source(self, source: str):\n",
    "        # Delete entities by a filter expression\n",
    "        return self.client.delete(\n",
    "            collection_name=self.collection_name,\n",
    "            filter=f\"source == '{source}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root path  /Users/pujanmaharjan/pdfs/agile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/pujanmaharjan/pdfs/agile/Kameron H. Clean Code. An Agile Guide to Software Craft 2023.pdf',\n",
       " '/Users/pujanmaharjan/pdfs/agile/akka/Abraham F. Akka in Action (MEAP v13) 2ed 2023.pdf']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants\n",
    "ROOT_DIR = \"/Users/pujanmaharjan/pdfs\"\n",
    "\n",
    "file_helper = FileHelper()\n",
    "\n",
    "files = []\n",
    "root_path = os.path.join(ROOT_DIR, \"agile\")\n",
    "print('root path ', root_path)\n",
    "file_helper.populate_file_paths(root_path, files)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pujanmaharjan/Projects/llm_public/langchain/.venv_langchain/lib/python3.10/site-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n",
      "/Users/pujanmaharjan/Projects/llm_public/langchain/.venv_langchain/lib/python3.10/site-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loader</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>pages_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PyMuPDFLoader</td>\n",
       "      <td>1.155494</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PyPDFium2Loader</td>\n",
       "      <td>1.429482</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PyPDFLoader</td>\n",
       "      <td>14.880094</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loader    elapsed  pages_count\n",
       "1    PyMuPDFLoader   1.155494          962\n",
       "2  PyPDFium2Loader   1.429482          962\n",
       "0      PyPDFLoader  14.880094          962"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment pdf loaders\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "pdf_loader_results = []\n",
    "pdf_loaders = [PyPDFLoader, PyMuPDFLoader, PyPDFium2Loader]\n",
    "# pdf_loaders = [PyPDFium2Loader]\n",
    "time_helper = TimeHelper()\n",
    "for pdf_loader in pdf_loaders:\n",
    "    start_time = time_helper.get_utc_now()\n",
    "    pages = file_helper.read_documents(files, pdf_loader, n_jobs=5)\n",
    "    pdf_loader_results.append({\"loader\": pdf_loader.__name__,\n",
    "                               \"elapsed\": time_helper.get_elapsed_seconds(start_time),\n",
    "                               \"pages_count\": len(pages)})\n",
    "    \n",
    "pdf_loader_results_df = pd.DataFrame(pdf_loader_results)\n",
    "pdf_loader_results_df.sort_values(by=\"elapsed\")\n",
    "\n",
    "# The result shows PyMuPDFLoader is fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722176474.899582 29062266 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722176474.913677 29062266 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722176474.942068 29062266 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722176474.998655 29062266 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n",
      "I0000 00:00:1722176475.111387 29062266 work_stealing_thread_pool.cc:320] WorkStealingThreadPoolImpl::PrepareFork\n"
     ]
    }
   ],
   "source": [
    "pages = file_helper.read_documents(files, PyMuPDFLoader, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/pujanmaharjan/pdfs/agile/Kameron H. Clean Code. An Agile Guide to Software Craft 2023.pdf', 'file_path': '/Users/pujanmaharjan/pdfs/agile/Kameron H. Clean Code. An Agile Guide to Software Craft 2023.pdf', 'page': 0, 'total_pages': 447, 'format': 'PDF 1.4', 'title': '677757029', 'author': 'Unknown', 'subject': '', 'keywords': '', 'creator': 'calibre (6.17.0) [http://calibre-ebook.com]', 'producer': 'calibre (6.17.0) [http://calibre-ebook.com]', 'creationDate': \"D:20240203035244+00'00'\", 'modDate': \"D:20240203105244+07'00'\", 'trapped': ''}, page_content='Clean Code: An Agile Guide to Software Craft\\n\\xa0\\nKameron Hussain and Frahaan Hussain\\n\\xa0\\nPublished by Sonar Publishing, 2023.')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = pages[0]\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '/Users/pujanmaharjan/pdfs/agile/Kameron H. Clean Code. An Agile Guide to Software Craft 2023.pdf',\n",
       " 'file_path': '/Users/pujanmaharjan/pdfs/agile/Kameron H. Clean Code. An Agile Guide to Software Craft 2023.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 447,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '677757029',\n",
       " 'author': 'Unknown',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'calibre (6.17.0) [http://calibre-ebook.com]',\n",
       " 'producer': 'calibre (6.17.0) [http://calibre-ebook.com]',\n",
       " 'creationDate': \"D:20240203035244+00'00'\",\n",
       " 'modDate': \"D:20240203105244+07'00'\",\n",
       " 'trapped': ''}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean Code: An Agile Guide to Software Craft\\n\\xa0\\nKameron Hussain and Frahaan Hussain\\n\\xa0\\nPublished by Sonar Publishing, 2023.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '/Users/pujanmaharjan/pdfs/agile/Kameron H. Clean Code. An Agile Guide to Software Craft 2023.pdf',\n",
       " 'file_path': '/Users/pujanmaharjan/pdfs/agile/Kameron H. Clean Code. An Agile Guide to Software Craft 2023.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 447,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '677757029',\n",
       " 'author': 'Unknown',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'calibre (6.17.0) [http://calibre-ebook.com]',\n",
       " 'producer': 'calibre (6.17.0) [http://calibre-ebook.com]',\n",
       " 'creationDate': \"D:20240203035244+00'00'\",\n",
       " 'modDate': \"D:20240203105244+07'00'\",\n",
       " 'trapped': '',\n",
       " 'text': 'Clean Code: An Agile Guide to Software Craft\\n\\xa0\\nKameron Hussain and Frahaan Hussain\\n\\xa0\\nPublished by Sonar Publishing, 2023.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = page.metadata | {'text': page.page_content}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"docs_collection\"\n",
    "chroma_db_repository = ChomaDbRepository(collection_name)\n",
    "#if file already exists, then delete them, and add again\n",
    "\n",
    "def add_to_db(pages, batch_size):\n",
    "    sources = list(set([p.metadata['source'] for p in pages]))\n",
    "    for source in sources:\n",
    "        source_data = chroma_db_repository.get_data_by_source(source)\n",
    "        if len(source_data[\"ids\"]) > 0:\n",
    "            print(\"previous data found so delete them \", source)\n",
    "            chroma_db_repository.delete_data_by_source(source)\n",
    "\n",
    "    time_helper = TimeHelper()\n",
    "    start_time = time_helper.get_utc_now()\n",
    "    iter_helper = IterHelper()\n",
    "\n",
    "    for page_batch in tqdm(iter_helper.batched(pages, batch_size), total=len(pages)/batch_size):\n",
    "        start_time_batch = time_helper.get_utc_now()\n",
    "        chroma_db_repository.add_to_collection(page_batch)\n",
    "        # print(f\"Added {batch_size} record in {time_helper.get_elapsed_seconds(start_time_batch)} seconds\")\n",
    "\n",
    "    total_elapsed = time_helper.get_elapsed_seconds(start_time)\n",
    "    print(f\"Added {len(pages)} records in {total_elapsed} seconds\")\n",
    "    return {\"batch_size\": batch_size, \"elapsed\": total_elapsed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [3,5]\n",
    "batch_size_results = []\n",
    "for batch_size in batch_sizes:\n",
    "    print(\"Batch size \", batch_size)\n",
    "    result = add_to_db(pages, batch_size)\n",
    "    batch_size_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size_results_df = pd.DataFrame(batch_size_results)\n",
    "batch_size_results_df.sort_values(by=\"elapsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[1,2],[3,4]]\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time  1e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "def log_execution_time(func):\n",
    "    @functools.wraps(func)\n",
    "    def log_execution_time_wrapper(*args, **kwargs):\n",
    "        time_helper = TimeHelper()\n",
    "        start_time = time_helper.get_utc_now()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time_helper.get_elapsed_seconds(start_time)\n",
    "        print(\"Elapsed time \", elapsed)\n",
    "        return result\n",
    "    \n",
    "    return log_execution_time_wrapper\n",
    "\n",
    "@log_execution_time\n",
    "def sum_num(a, b):\n",
    "    return a + b\n",
    "\n",
    "sum_num(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sum_num'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_num.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722173139.054879 29062266 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(uri=\"http://localhost:19530\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.has_collection(collection_name=\"demo_collection\"):\n",
    "    client.drop_collection(collection_name=\"demo_collection\")\n",
    "client.create_collection(\n",
    "    collection_name=\"demo_collection\",\n",
    "    dimension=768,  # The vectors we will use in this demo has 768 dimensions\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
