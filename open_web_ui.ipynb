{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poo5zan/llm_public/blob/main/open_web_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "I, Pujan Maharjan, am a Software Engineer. You can find more about me at my linkedIn: https://www.linkedin.com/in/pujan-mhjn/\n",
        "\n",
        "\n",
        "This notebook demonstrates deploying open-web UI in google colab. So you can use it for FREE for demo purposes.\n",
        "\n",
        "\"Open WebUI is an extensible, feature-rich, and user-friendly self-hosted WebUI designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs\". More information can be found in it's official page: https://docs.openwebui.com/\n",
        "\n"
      ],
      "metadata": {
        "id": "phSdXx2sJNEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Ollama\n",
        "\n",
        "And pull a model from ollama library\n",
        "https://ollama.com/library\n",
        "\n",
        "Here, in this example, we used llama3, However, you can use any"
      ],
      "metadata": {
        "id": "6IKpUMfasMXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and Start Ollama\n",
        "# The command to start ollama i.e 'ollama serve' has been started in a new process.\n",
        "# If you just run the command !ollama serve, then it will run the process in the main UI thread,\n",
        "# thus blocking everything. You can try that too, and then revert back to this process method\n",
        "!curl https://ollama.ai/install.sh | sh\n",
        "import subprocess\n",
        "process_serve = subprocess.Popen(\"ollama serve\", shell=True)"
      ],
      "metadata": {
        "id": "BBqHd2CMsO40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pull a model. Here we will be using llama3.\n",
        "# You can pick any other model available in ollama library\n",
        "# https://ollama.com/library\n",
        "!ollama pull llama3"
      ],
      "metadata": {
        "id": "tGxo4HOj1SOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull gemma2"
      ],
      "metadata": {
        "id": "vkoz5q_l8teH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expose a public URL to access\n",
        "\n",
        "We will be using ngrok"
      ],
      "metadata": {
        "id": "VizU50cfsU0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "Bwa4Z1FMv_B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ngrok config add-authtoken <your-personal-token>\n",
        "# https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "!ngrok config add-authtoken <token-here>"
      ],
      "metadata": {
        "id": "EahjvA6yzK0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8081).public_url\n",
        "print(\"public url \", public_url)"
      ],
      "metadata": {
        "id": "QWoGarY9vg66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upgrade Python\n",
        "\n",
        "As of this writing on 3rd July, 2024, the default python version in google colab T4 instance is 3.10. However, the open-webui requires python version >3.10 < 3.12. Thus, we install python 3.11"
      ],
      "metadata": {
        "id": "euREaervrqu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# install python 3.11\n",
        "sudo apt-get update -y\n",
        "sudo apt-get install python3.11\n",
        "\n",
        "sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 2\n",
        "curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "python get-pip.py\n",
        "\n",
        "# create a virtual environment,\n",
        "# the dependencies for open-webui got some conflict with the default dependencies installed\n",
        "# Thus, it's always safe to create a virtual environment\n",
        "pip install virtualenv\n",
        "virtualenv pu_venv\n",
        "# Install open-webui\n",
        "source /content/pu_venv/bin/activate; pip install open-webui\n",
        "# Run open-webui in port 8081\n",
        "source /content/pu_venv/bin/activate; open-webui serve --port 8081"
      ],
      "metadata": {
        "id": "yukWpl4ggSbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ulYeqyfgqoB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}